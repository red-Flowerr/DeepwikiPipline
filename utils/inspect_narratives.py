#!/usr/bin/env python3
"""Inspect DeepWiki narrative exports for quick quality checks.

This CLI reads a JSON export generated by the DeepWiki pipeline (typically
``result_data/verl_narratives.json``) and reports useful statistics such as
pass ratios, sentence count violations, and critic failures.  You can also
sample rewritten blocks for manual spot checks.
"""

from __future__ import annotations

import argparse
import json
import random
import re
import sys
from collections import Counter
from pathlib import Path
from typing import Iterable, List, Tuple


SENTENCE_SPLIT_RE = re.compile(r"(?<=[.!?])\s+")


def load_blocks(path: Path) -> List[dict]:
    try:
        data = json.loads(path.read_text())
    except FileNotFoundError as exc:
        raise SystemExit(f"File not found: {path}") from exc
    except json.JSONDecodeError as exc:
        raise SystemExit(f"Failed to decode JSON: {exc}") from exc
    if not isinstance(data, list):
        raise SystemExit("Expected top-level JSON array of block records.")
    return data


def split_sentences(text: str) -> List[str]:
    stripped = text.strip()
    if not stripped:
        return []
    return [sentence.strip() for sentence in SENTENCE_SPLIT_RE.split(stripped) if sentence.strip()]


def compute_summary(blocks: Iterable[dict]) -> Tuple[int, Counter]:
    verdicts = Counter()
    total = 0
    for block in blocks:
        verdicts[block.get("verdict", "UNKNOWN").upper()] += 1
        total += 1
    return total, verdicts


def find_sentence_violations(blocks: Iterable[dict], min_sentences: int, max_sentences: int) -> List[dict]:
    offenders: List[dict] = []
    for block in blocks:
        sentences = split_sentences(block.get("narrative", ""))
        if not (min_sentences <= len(sentences) <= max_sentences):
            clone = dict(block)
            clone["_sentence_count"] = len(sentences)
            offenders.append(clone)
    return offenders


def iter_failures(blocks: Iterable[dict]) -> Iterable[dict]:
    for block in blocks:
        verdict = block.get("verdict", "").upper()
        misalignment = str(block.get("misalignment") or "").lower()
        if verdict != "PASS" or (misalignment and misalignment != "none"):
            yield block


def print_block(block: dict, *, show_code: bool = False) -> None:
    page = block.get("page", "<unknown page>")
    section = block.get("section", "<unknown section>")
    verdict = block.get("verdict", "UNKNOWN")
    misalignment = block.get("misalignment", "none")
    print("=" * 72)
    print(f"{page} :: {section}")
    print(f"Verdict: {verdict} | Misalignment: {misalignment}")
    critic = block.get("critic", "").strip()
    if critic:
        print("Critic:", critic)
    print("\nNarrative:\n", block.get("narrative", "").strip())
    if show_code:
        code_blocks = block.get("code_blocks") or []
        for idx, code_block in enumerate(code_blocks, start=1):
            code = code_block.get("code", "").strip()
            if not code:
                continue
            reference = code_block.get("reference", "")
            header = f"\nCode {idx}"
            if reference:
                header += f" [{reference}]"
            print(header + ":\n```\n" + code + "\n```")
    print()


def parse_args(argv: List[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "path",
        nargs="?",
        type=Path,
        default=Path("result_data/verl_narratives.json"),
        help="Path to the narrative JSON export (default: result_data/verl_narratives.json)",
    )
    parser.add_argument(
        "--show-fails",
        action="store_true",
        help="Print blocks that failed the critic or report misalignment.",
    )
    parser.add_argument(
        "--check-sentences",
        action="store_true",
        help="Report rewrites that do not fall within the expected sentence count.",
    )
    parser.add_argument(
        "--min-sentences",
        type=int,
        default=2,
        help="Minimum sentences expected in each rewrite (default: 2).",
    )
    parser.add_argument(
        "--max-sentences",
        type=int,
        default=3,
        help="Maximum sentences expected in each rewrite (default: 3).",
    )
    parser.add_argument(
        "--sample",
        type=int,
        default=0,
        help="Randomly display N blocks for manual inspection.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=None,
        help="Random seed used when sampling blocks.",
    )
    parser.add_argument(
        "--page",
        type=str,
        default=None,
        help="Filter to a specific page title (case-insensitive contains).",
    )
    parser.add_argument(
        "--section",
        type=str,
        default=None,
        help="Filter to a specific section heading (case-insensitive contains).",
    )
    parser.add_argument(
        "--show-code",
        action="store_true",
        help="Include code snippets when printing sampled sections.",
    )
    return parser.parse_args(argv)


def apply_filters(blocks: Iterable[dict], page: str | None, section: str | None) -> List[dict]:
    if not page and not section:
        return list(blocks)
    filtered = []
    page_filter = page.lower() if page else None
    section_filter = section.lower() if section else None
    for block in blocks:
        if page_filter and page_filter not in block.get("page", "").lower():
            continue
        if section_filter and section_filter not in block.get("section", "").lower():
            continue
        filtered.append(block)
    return filtered


def main(argv: List[str]) -> None:
    args = parse_args(argv)
    blocks = load_blocks(args.path)
    blocks = apply_filters(blocks, args.page, args.section)
    if not blocks:
        print("No blocks matched the provided filters.")
        return

    total, verdicts = compute_summary(blocks)
    pass_count = verdicts.get("PASS", 0)
    fail_count = total - pass_count
    unique_pages = {block.get("page") for block in blocks}
    unique_sections = {block.get("section") for block in blocks}
    pass_ratio = pass_count / total if total else 0.0
    print(f"Sections: {total}")
    print(f"Unique pages: {len(unique_pages)} | Unique sections: {len(unique_sections)}")
    print("Verdicts:")
    for verdict, count in verdicts.most_common():
        ratio = count / total if total else 0.0
        print(f"  {verdict:<10} {count:>5} ({ratio:.1%})")
    print(f"Pass ratio: {pass_ratio:.1%} | Failures: {fail_count}")

    if args.check_sentences:
        offenders = find_sentence_violations(blocks, args.min_sentences, args.max_sentences)
        print(f"\nSentence count violations: {len(offenders)}")
        for block in offenders[:10]:
            print(
                f"- {block.get('page')} :: {block.get('section')}, "
                f"{block.get('_sentence_count', 0)} sentences",
            )
        if len(offenders) > 10:
            print(f"  ... {len(offenders) - 10} more")

    if args.show_fails:
        failures = list(iter_failures(blocks))
        print(f"\nCritic failures or misalignments: {len(failures)}")
        for block in failures:
            print_block(block, show_code=args.show_code)

    if args.sample:
        if args.seed is not None:
            random.seed(args.seed)
        sample_size = min(args.sample, len(blocks))
        print(f"\nRandom sample ({sample_size} of {len(blocks)}):")
        for block in random.sample(blocks, sample_size):
            print_block(block, show_code=args.show_code)


if __name__ == "__main__":
    main(sys.argv[1:])
